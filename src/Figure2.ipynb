{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalised Forest Tuning - Figure 2\n",
    "\n",
    "This is the code used to generate figure 2 of the paper \"Generalising Random Forest Parameter Optimisation to Include Stability and Cost\" by CHB Liu, BP Chamberlain, DA Little, A Cardoso (2017).\n",
    "\n",
    "Please ensure you are using the anaconda environment `gft_env`. This is usually indicated by successfully importing the libraries below. If the library import resulted in any error, please try and run the `./setup_environment.sh` script again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pandas as pd # You need pandas 0.19+\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from data_loader import *\n",
    "#from evaluator import *\n",
    "#from pybo import solve_bayesopt\n",
    "#from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Orange Small Dataset\n",
    "\n",
    "We use the **upselling** labels here. The dataset is sliced in half for training (first half) and validation (second half)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orange_small_features, _, _, orange_small_upselling_labels = \\\n",
    "    get_and_process_orange_small_data()\n",
    "    \n",
    "orange_small_features_train, orange_small_features_val, \\\n",
    "orange_small_upselling_labels_train, orange_small_upselling_labels_val = \\\n",
    "    split_train_val_data(orange_small_features,\n",
    "                         orange_small_upselling_labels,\n",
    "                         prop=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributional Plot of Prediction Deltas\n",
    "\n",
    "- Training proportion: 1 (of all available training data - 1st half of the orange small training dataset)\n",
    "- Number of trees: [8, 32, 128]\n",
    "- Max. tree depth: 10\n",
    " \n",
    "Note: Due to the random nature in random forest models, it may not be possible to exactly duplicate the distribution shown in the paper. Though the distribution should become more concentrated with increasing number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trees = [8, 32, 128]\n",
    "num_runs = 11\n",
    "\n",
    "# Reserve some space to store the predictions\n",
    "pred = np.zeros(shape=(num_runs, orange_small_features_val.shape[0]))\n",
    "\n",
    "# Initialise figure\n",
    "fig = plt.figure(figsize=(8, 3.5))\n",
    "\n",
    "# Set common labels on the large subplot\n",
    "# Turn off axis lines and ticks of the big subplot\n",
    "ax = fig.add_subplot(111)\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.tick_params(labelcolor='w', top='off', bottom='off',\n",
    "               left='off', right='off')\n",
    "ax.set_xlabel('Prediction delta ($\\hat{y}_i^{(j+1)} - \\hat{y}_i^{(j)}$)')\n",
    "ax.set_ylabel('Density')\n",
    "    \n",
    "for i in num_trees:\n",
    "    \n",
    "    RF = RandomForestClassifier(max_depth=10, n_estimators=i)\n",
    "    \n",
    "    # Compute prediction for all validation data points\n",
    "    for j in range(0, num_runs):\n",
    "        RF.fit(orange_small_features_train, \n",
    "               orange_small_upselling_labels_train)\n",
    "        pred[j] = RF.predict_proba(orange_small_features_val)[:, 1]\n",
    "        \n",
    "    # Compute prediction deltas\n",
    "    # Here we append the prediction deltas to get the \"averaged out\"\n",
    "    # distribution on prediction deltas (this is different to plotting\n",
    "    # the distribution of the average prediction deltas)\n",
    "    pred_deltas = np.array([])\n",
    "    for j in range(0, num_runs-1):\n",
    "        pred_deltas = np.append(pred_deltas, pred[j+1] - pred[j])\n",
    "    \n",
    "    # Construct plot\n",
    "    ax = fig.add_subplot(1, 3, num_trees.index(i) + 1)\n",
    "    ax.hist(pred_deltas, bins=30, range=(-0.15, 0.15), normed=True)\n",
    "    ax.set_xlim(-0.15, 0.15)\n",
    "    ax.set_ylim(0, 42)\n",
    "    ax.set_xticks([-0.1, 0, 0.1])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "# Either save the figure or show on screen\n",
    "# plt.savefig(\"../results/prediction_delta_distribution.pdf\", \n",
    "#             bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:gft_env]",
   "language": "python",
   "name": "conda-env-gft_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
